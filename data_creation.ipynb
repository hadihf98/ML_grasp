{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from utils.loader import Loader\n",
    "from utils.image import draw_around_box, draw_pose, get_area_of_interest\n",
    "from utils.trainer import Trainer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 22002 grasp attempts.\n",
      "Loaded action of episode 2020-06-02-15-24-22-937 with reward: 0 at pose: {'x': 0.022446519796532102, 'y': -0.06984341434605564, 'z': -0.004660785129988632, 'a': -1.1223572697521091, 'b': -0.0005229883538433455, 'c': 0.00027451530815625347, 'd': 0.05}\n",
      "{'pose': {'x': 0.022446519796532102, 'y': -0.06984341434605564, 'z': -0.004660785129988632, 'a': -1.1223572697521091, 'b': -0.0005229883538433455, 'c': 0.00027451530815625347, 'd': 0.05}, 'type': 'grasp', 'safe': 1, 'reward': 0, 'collision': True, 'estimated_reward': -1, 'method': 'Random', 'images': {'rd-v': {'info': {'pixel_size': 2000.0, 'min_depth': 0.2199999988079071, 'max_depth': 0.4099999964237213}, 'pose': {'x': -0.000301147668394397, 'y': -7.021008078000879e-05, 'z': 0.3499887353031891, 'a': -0.0005321141969116816, 'b': -0.00047430654395697047, 'c': -0.00035200678608271474}}, 'rc-v': {'info': {'pixel_size': 2000.0, 'min_depth': 0.2199999988079071, 'max_depth': 0.4099999964237213}, 'pose': {'x': -0.000301147668394397, 'y': -7.021008078000879e-05, 'z': 0.3499887353031891, 'a': -0.0005321141969116816, 'b': -0.00047430654395697047, 'c': -0.00035200678608271474}}}, 'bin': 'Left', 'bin_episode': '2020-06-02-15-20-55-252', 'final_pose': {'x': 0.5503379200516669, 'y': -0.10335715654030103, 'z': 0.007443712908225791, 'a': 0.4492912299547017, 'b': -0.0013055480917847765, 'c': -0.000832086478698084, 'd': 0.0}, 'execution_time': 12.607351303100586, 'box_data': {'contour': [[0.08499999999999999, 0.13449999999999998, 0.068], [0.08499999999999999, -0.1475, 0.068], [-0.089, -0.1475, 0.068], [-0.089, 0.13449999999999998, 0.068]], 'color': [117, 66, 0]}, 'episode_id': '2020-06-02-15-24-22-937'}\n",
      "3\n",
      "Episode keys:  ['id', 'actions']\n",
      "Action keys:  ['pose', 'type', 'safe', 'reward', 'collision', 'estimated_reward', 'method', 'images', 'bin', 'bin_episode', 'final_pose', 'execution_time', 'box_data']\n"
     ]
    }
   ],
   "source": [
    "# 1. Init loader, this will load the (non-image) dataset into memory\n",
    "loader = Loader()\n",
    "print(f'Dataset has {len(loader)} grasp attempts.')\n",
    "\n",
    "\n",
    "# 2. Load an action and/or image\n",
    "episode_index = 56\n",
    "action = loader.get_action(episode_index, action_id=0)\n",
    "print(f\"Loaded action of episode {action['episode_id']} with reward: {action['reward']} at pose: {action['pose']}\")\n",
    "print(action)\n",
    "\n",
    "rgbd_image = loader.get_image(episode_index, action_id=0, camera='rcd')\n",
    "\n",
    "# You can also load action and images at once\n",
    "action, rgb_image = loader.get_action(episode_index, action_id=0, images=['rc'])\n",
    "\n",
    "\n",
    "# 3. Draw action and box on image for visualization\n",
    "draw_around_box(rgbd_image, action['box_data'])\n",
    "draw_pose(rgbd_image, action['pose'])\n",
    "# 4. Get image area by an affine transformation. By specifying size_result, we can scale the final image down.\n",
    "area = get_area_of_interest(rgbd_image, action['pose'], size_cropped=(200, 200), size_result=(150, 150))  # [px]\n",
    "cv2.imshow('area', area)\n",
    "cv2.waitKey(0)\n",
    "print(\"3\")\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# 5. Iterate over all actions\n",
    "for index, episode in enumerate(loader.yield_episodes()):\n",
    "    print('Episode keys: ', list(episode.keys()))\n",
    "    print('Action keys: ', list(episode['actions'][0].keys()))\n",
    "\n",
    "    # loader.get_image(index, action_id=0, camera='rcd')\n",
    "    break\n",
    "\n",
    "\n",
    "# 6. Split into Training / Validation / Test set\n",
    "# training_set, validation_set, test_set = Trainer.split(loader.episodes, seed=42)\n",
    "# print(f'Training set length: {len(training_set)}')\n",
    "# print(f'Validation set length: {len(validation_set)}')\n",
    "# print(f'Test set length: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22002it [00:49, 440.79it/s] \n"
     ]
    }
   ],
   "source": [
    "# Saving images and data into training_data_img list\n",
    "\n",
    "data_img_d_small = []\n",
    "# test_data_img = []\n",
    "# validation_data_img = []\n",
    "\n",
    "loader = Loader()\n",
    "# training_set, validation_set, test_set = Trainer.split(loader.episodes, seed=42)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for index, episode in tqdm(enumerate(loader.yield_episodes())):\n",
    "    action = episode['actions'][0]\n",
    "\n",
    "    id_ = Trainer.get_index(action)\n",
    "    if id_ == 0:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    depth_img = loader.get_image(index, action_id=0, camera='rcd')\n",
    "    draw_around_box(depth_img, action['box_data'])\n",
    "    draw_pose(depth_img, action['pose'])\n",
    "    area = get_area_of_interest(depth_img, action['pose'], size_cropped=(200, 200), size_result=(150, 150))\n",
    "    area = cv2.cvtColor(area, cv2.COLOR_BGR2GRAY)\n",
    "    area = cv2.normalize(area, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    data_img_d_small.append([area, action['reward']])\n",
    "#     break\n",
    "# cv2.imshow('area', area)\n",
    "# cv2.waitKey(0)\n",
    "# print(\"works\")\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4845"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4845\n"
     ]
    }
   ],
   "source": [
    "print(len(data_img_d_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[ 54,  29,  29, ...,  33,  33,  29],\n",
       "       [ 29,  29,  29, ...,  30,  29,  29],\n",
       "       [ 29,  29,  42, ...,  52,  45,  54],\n",
       "       ...,\n",
       "       [ 29,  30,  35, ...,  69,  82, 123],\n",
       "       [ 29,  30,  37, ...,  71,  73,  60],\n",
       "       [ 29,  29,  30, ...,  70,  74,  56]], dtype=uint8),\n",
       "        1.0],\n",
       "       [array([[ 29,  29,  29, ...,  29,  29,  29],\n",
       "       [ 29,  29,  56, ...,  91,  98,  83],\n",
       "       [ 29,  29,  96, ..., 122, 118, 103],\n",
       "       ...,\n",
       "       [ 33,  29,  77, ...,  53,  53,  53],\n",
       "       [ 36,  29,  66, ...,  53,  53,  53],\n",
       "       [ 29,  29,  47, ...,  53,  53,  53]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 30,  30,  30, ...,  30,  30,  30],\n",
       "       [ 30,  27,  21, ...,  19,  25,  23],\n",
       "       [ 30,  26,  24, ...,  18,  19,  27],\n",
       "       ...,\n",
       "       [ 30,  44, 122, ...,  61,  60,  30],\n",
       "       [ 30,  71,  63, ...,  53,  58,  40],\n",
       "       [ 30,  30,  30, ...,  30,  30,  32]], dtype=uint8),\n",
       "        0],\n",
       "       ...,\n",
       "       [array([[49, 49, 49, ..., 49, 49, 49],\n",
       "       [49, 54, 63, ..., 49, 49, 49],\n",
       "       [49, 67, 89, ..., 81, 86, 57],\n",
       "       ...,\n",
       "       [49, 61, 86, ..., 90, 84, 60],\n",
       "       [49, 57, 89, ..., 91, 85, 64],\n",
       "       [49, 50, 61, ..., 93, 85, 67]], dtype=uint8),\n",
       "        1.0],\n",
       "       [array([[30, 30, 30, ..., 42, 43, 39],\n",
       "       [30, 32, 30, ..., 30, 32, 30],\n",
       "       [30, 34, 34, ..., 52, 53, 30],\n",
       "       ...,\n",
       "       [30, 30, 53, ..., 56, 56, 47],\n",
       "       [30, 37, 53, ..., 55, 56, 51],\n",
       "       [30, 30, 50, ..., 54, 53, 45]], dtype=uint8),\n",
       "        1.0],\n",
       "       [array([[ 52,  52,  47, ...,  56,  52,  52],\n",
       "       [ 52,  52,  52, ...,  52,  53,  52],\n",
       "       [ 52,  46,  40, ..., 193, 201, 106],\n",
       "       ...,\n",
       "       [ 52,  66, 201, ...,  85,  83,  79],\n",
       "       [ 52,  52, 199, ...,  84,  83,  81],\n",
       "       [ 52,  52, 177, ...,  79,  78,  73]], dtype=uint8),\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array(data_img_d_small)\n",
    "np.random.shuffle(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small, validate_small, test_small = np.split(d, [int(.6*len(d)), int(.8*len(d))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2907 969 969\n"
     ]
    }
   ],
   "source": [
    "print(len(train_small),len(test_small),len(validate_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22002it [00:52, 421.96it/s]\n"
     ]
    }
   ],
   "source": [
    "data_img_d_med = []\n",
    "\n",
    "loader = Loader()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for index, episode in tqdm(enumerate(loader.yield_episodes())):\n",
    "    action = episode['actions'][0]\n",
    "\n",
    "    id_ = Trainer.get_index(action)\n",
    "    if id_ == 1:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    depth_img = loader.get_image(index, action_id=0, camera='rcd')\n",
    "    draw_around_box(depth_img, action['box_data'])\n",
    "    draw_pose(depth_img, action['pose'])\n",
    "    area = get_area_of_interest(depth_img, action['pose'], size_cropped=(200, 200), size_result=(150, 150))\n",
    "    area = cv2.cvtColor(area, cv2.COLOR_BGR2GRAY)\n",
    "    area = cv2.normalize(area, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    data_img_d_med.append([area, action['reward']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[51, 51, 51, ..., 51, 51, 51],\n",
       "       [51, 68, 77, ..., 50, 43, 51],\n",
       "       [51, 80, 92, ...,  0,  0, 51],\n",
       "       ...,\n",
       "       [51, 92, 92, ..., 91, 83, 52],\n",
       "       [51, 92, 92, ..., 89, 84, 51],\n",
       "       [51, 59, 54, ..., 76, 69, 51]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[43, 45, 51, ..., 43, 43, 43],\n",
       "       [43, 57, 77, ..., 77, 77, 51],\n",
       "       [43, 52, 77, ..., 77, 77, 57],\n",
       "       ...,\n",
       "       [43, 72, 80, ..., 68, 72, 43],\n",
       "       [43, 56, 59, ..., 65, 65, 43],\n",
       "       [43, 43, 43, ..., 43, 43, 43]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[37, 37, 37, ..., 37, 37, 37],\n",
       "       [37, 37, 49, ..., 62, 41, 45],\n",
       "       [37, 37, 55, ..., 66, 66, 66],\n",
       "       ...,\n",
       "       [37, 37, 33, ..., 36, 39, 40],\n",
       "       [37, 37, 33, ..., 34, 39, 43],\n",
       "       [37, 37, 36, ..., 35, 38, 39]], dtype=uint8),\n",
       "        1.0],\n",
       "       ...,\n",
       "       [array([[42, 42, 42, ..., 42, 42, 42],\n",
       "       [42, 42, 46, ..., 60, 50, 42],\n",
       "       [42, 46, 37, ..., 76, 66, 42],\n",
       "       ...,\n",
       "       [42, 70, 72, ..., 63, 63, 43],\n",
       "       [42, 58, 67, ..., 63, 63, 43],\n",
       "       [42, 42, 48, ..., 56, 54, 42]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 51,  51,  51, ...,  51,  51,  51],\n",
       "       [ 51,  70,  74, ...,  58,  51,  51],\n",
       "       [ 51, 157, 237, ..., 112,  27,  43],\n",
       "       ...,\n",
       "       [ 51, 109, 156, ...,  92,  92,  92],\n",
       "       [ 51,  98, 154, ...,  92,  92,  92],\n",
       "       [ 51,  56,  51, ...,  92,  92,  92]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 41,  40,  40, ...,  40,  40,  40],\n",
       "       [ 40,  45, 114, ...,  52,  40,  40],\n",
       "       [ 40,  40, 179, ..., 139, 140, 105],\n",
       "       ...,\n",
       "       [ 40, 166, 224, ..., 199, 200,  87],\n",
       "       [ 40, 161, 229, ..., 196, 198,  40],\n",
       "       [ 40,  66,  55, ..., 194, 176,  44]], dtype=uint8),\n",
       "        1.0]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.array(data_img_d_med)\n",
    "np.random.shuffle(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_med, validate_med, test_med = np.split(m, [int(.6*len(m)), int(.8*len(m))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22002it [01:01, 359.32it/s]\n"
     ]
    }
   ],
   "source": [
    "data_img_d_large = []\n",
    "\n",
    "loader = Loader()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for index, episode in tqdm(enumerate(loader.yield_episodes())):\n",
    "    action = episode['actions'][0]\n",
    "\n",
    "    id_ = Trainer.get_index(action)\n",
    "    if id_ == 2:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    depth_img = loader.get_image(index, action_id=0, camera='rcd')\n",
    "    draw_around_box(depth_img, action['box_data'])\n",
    "    draw_pose(depth_img, action['pose'])\n",
    "    area = get_area_of_interest(depth_img, action['pose'], size_cropped=(200, 200), size_result=(150, 150))\n",
    "    area = cv2.cvtColor(area, cv2.COLOR_BGR2GRAY)\n",
    "    area = cv2.normalize(area, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    data_img_d_large.append([area, action['reward']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[ 45,  54,  43, ...,  43,  43,  43],\n",
       "       [ 43,  43,  43, ...,  48,  43,  55],\n",
       "       [ 43,  61,  61, ...,  94,  92,  62],\n",
       "       ...,\n",
       "       [ 43, 139, 137, ...,  76,  76,  43],\n",
       "       [ 43, 126, 160, ...,  76,  71,  43],\n",
       "       [ 43, 172, 145, ...,  76,  66,  43]], dtype=uint8),\n",
       "        1.0],\n",
       "       [array([[ 76,  75,  75, ...,  75,  75,  75],\n",
       "       [ 75,  94,  75, ...,  85,  75,  88],\n",
       "       [ 75, 101, 134, ..., 150, 138, 113],\n",
       "       ...,\n",
       "       [ 75,  75, 222, ..., 159, 149,  75],\n",
       "       [ 75, 104, 218, ..., 147, 142, 105],\n",
       "       [ 83,  75, 224, ..., 140, 136,  98]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[29, 29, 29, ..., 29, 29, 29],\n",
       "       [29, 31, 31, ..., 29, 29, 29],\n",
       "       [29, 31, 27, ..., 24, 25, 29],\n",
       "       ...,\n",
       "       [29, 41, 62, ..., 42, 44, 33],\n",
       "       [29, 38, 65, ..., 37, 36, 32],\n",
       "       [29, 30, 31, ..., 35, 34, 31]], dtype=uint8),\n",
       "        1.0],\n",
       "       ...,\n",
       "       [array([[31, 31, 31, ..., 31, 31, 31],\n",
       "       [31, 31, 13, ..., 36, 30, 31],\n",
       "       [31, 10,  0, ..., 43, 43, 37],\n",
       "       ...,\n",
       "       [31, 31, 33, ..., 59, 61, 43],\n",
       "       [32, 34, 46, ..., 58, 59, 45],\n",
       "       [31, 31, 43, ..., 52, 60, 39]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[30, 29, 29, ..., 29, 29, 29],\n",
       "       [29, 29, 29, ..., 78, 67, 44],\n",
       "       [29, 29, 48, ..., 88, 86, 48],\n",
       "       ...,\n",
       "       [47, 31, 78, ..., 53, 53, 53],\n",
       "       [38, 29, 74, ..., 53, 53, 53],\n",
       "       [29, 29, 66, ..., 46, 29, 31]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 39,  39,  39, ...,  39,  39,  39],\n",
       "       [ 42,  49,  40, ...,  68,  51,  39],\n",
       "       [ 59, 103,  91, ...,  73,  51,  39],\n",
       "       ...,\n",
       "       [ 39,  57,  57, ...,   0,   0,  39],\n",
       "       [ 39,  58,  65, ...,   0,   0,  39],\n",
       "       [ 39,  47,  49, ...,  39,  39,  39]], dtype=uint8),\n",
       "        1.0]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array(data_img_d_med)\n",
    "np.random.shuffle(l)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_large, validate_large, test_large = np.split(l, [int(.6*len(l)), int(.8*len(l))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22002it [00:59, 369.81it/s]\n"
     ]
    }
   ],
   "source": [
    "data_img_d_xlarge = []\n",
    "\n",
    "loader = Loader()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for index, episode in tqdm(enumerate(loader.yield_episodes())):\n",
    "    action = episode['actions'][0]\n",
    "\n",
    "    id_ = Trainer.get_index(action)\n",
    "    if id_ == 3:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    depth_img = loader.get_image(index, action_id=0, camera='rcd')\n",
    "    draw_around_box(depth_img, action['box_data'])\n",
    "    draw_pose(depth_img, action['pose'])\n",
    "    area = get_area_of_interest(depth_img, action['pose'], size_cropped=(200, 200), size_result=(150, 150))\n",
    "    area = cv2.cvtColor(area, cv2.COLOR_BGR2GRAY)\n",
    "    area = cv2.normalize(area, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    data_img_d_xlarge.append([area, action['reward']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[ 30,  30,  30, ...,  30,  30,  30],\n",
       "       [ 30,  34,  39, ...,  48,  45,  33],\n",
       "       [ 30,  38,  46, ...,  54,  54,  34],\n",
       "       ...,\n",
       "       [ 30,  37,  76, ...,   9,   0,  18],\n",
       "       [ 30,  50, 105, ...,  66,   6,  21],\n",
       "       [ 30,  30,  37, ...,  30,  30,  29]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 30,  30,  30, ...,  30,  30,  30],\n",
       "       [ 30,  30,  34, ...,  24,  24,  30],\n",
       "       [ 30,  32,  58, ...,  22,  21,  30],\n",
       "       ...,\n",
       "       [ 30,  96, 133, ...,  46,  44,  30],\n",
       "       [ 30,  83, 129, ...,  45,  42,  31],\n",
       "       [ 30,  67, 121, ...,  38,  34,  30]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[103,  60,  60, ...,  60,  60,  60],\n",
       "       [ 89,  63, 125, ..., 158, 127, 163],\n",
       "       [ 60,  60, 190, ..., 176, 173, 129],\n",
       "       ...,\n",
       "       [ 60,  62,  78, ...,  78,  79,  78],\n",
       "       [ 60,  60,  77, ...,  78,  78,  73],\n",
       "       [ 60,  66,  71, ...,  61,  60,  60]], dtype=uint8),\n",
       "        0],\n",
       "       ...,\n",
       "       [array([[ 48,  44,  44, ...,  44,  44,  44],\n",
       "       [ 44,  44,  53, ...,  24,  14,  27],\n",
       "       [ 45,  81, 102, ...,  12,  12,  22],\n",
       "       ...,\n",
       "       [ 44, 207, 213, ...,  84,  84,  44],\n",
       "       [ 44, 154, 214, ...,  84,  84,  65],\n",
       "       [ 44, 111, 185, ...,  64,  84,  84]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 18,  18,  18, ...,  18,  17,  18],\n",
       "       [ 18,  19,  24, ...,  17,  14,   9],\n",
       "       [ 18,  27,  27, ...,  36,  15,  12],\n",
       "       ...,\n",
       "       [ 18, 106, 107, ...,  53,  53,  22],\n",
       "       [ 24,  96, 104, ...,  56,  57,  40],\n",
       "       [ 18,  18,  36, ...,  37,  34,  18]], dtype=uint8),\n",
       "        0],\n",
       "       [array([[ 43,  43,  80, ...,  43,  43,  43],\n",
       "       [ 85,  54, 255, ...,  88, 124, 112],\n",
       "       [ 43,  89, 253, ..., 128, 146, 106],\n",
       "       ...,\n",
       "       [ 43,  54,  77, ...,  77,  77,  63],\n",
       "       [ 49,  47,  76, ...,  77,  77,  76],\n",
       "       [ 44,  46,  56, ...,  77,  66,  61]], dtype=uint8),\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl = np.array(data_img_d_med)\n",
    "np.random.shuffle(xl)\n",
    "xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xlarge, validate_xlarge, test_xlarge = np.split(xl, [int(.6*len(xl)), int(.8*len(xl))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when need to save\n",
    "filename = 'training_data_d_0.025'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(train_small,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'test_data_d_0.025'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(test_small,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'validate_data_d_0.025'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(validate_small,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'training_data_d_0.05'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(train_med,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'test_data_d_0.05'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(test_med,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'validate_data_d_0.05'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(validate_med,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'training_data_d_0.07'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(train_large,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'test_data_d_0.07'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(test_large,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'validate_data_d_0.07'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(validate_large,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'training_data_d_0.086'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(train_xlarge,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'test_data_d_0.086'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(test_xlarge,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'validate_data_d_0.086'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(validate_xlarge,outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
